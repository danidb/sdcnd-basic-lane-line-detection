{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Finding Lane Lines on the Road** \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Pipeline \n",
    "The pipeline implemented here consists of 11 steps, described below. \n",
    "\n",
    "#### 1. Alter image saturation and contrast\n",
    "As in the 'challenge' video, yellow lane lines can be difficult to identify in bright sunlight, and on irregular road surfaces which are not a convenient shade of black. Increasing the saturation of the image enables easier detection of yellow lane lines. Coupled with a contrast adjustment, it becomes possible to recognize the yellow lane lines in the challenge video during the two-second interval of bright sunlight, $~0:04$ to $~0:06$. \n",
    "\n",
    "#### 2. Convert to grayscale \n",
    "To enable the detection of edges, the image must be converted to grayscale, as described in the accompanying lessons. \n",
    "\n",
    "#### 3. Apply a Gaussian filter  \n",
    "A gaussian blur filter with a kernel of size 3 is applied as a means of noise reduction, and to ensure that the most prominent lines in the image are more easily detected in the following steps. \n",
    "\n",
    "#### 4. Canny edge detection \n",
    "The Canny transform is applied to the image, indicating the pixels where the image gradient is above a certain threshold. \n",
    "\n",
    "#### 5. Define region of interest (ROI) \n",
    "The region of interest is statically defined, as a trapezoid whose two longest edges are approximately parallel to the left, and right lane lines respectively. \n",
    "\n",
    "#### 6. Detection of line segments via the hough transform \n",
    "Applying the hough transform, line segments are detected. Line segments are then seperated by the lane to which they appear to belong, based on their slope, $m$. Recalling that the origin is in the upper left corner of the frame, we define lines with $m > 0$ to be part of the right lane, and lines with $m \\leq 0$ to be part of the left lane. **Each step below marked with an (L/R) is performed separately for each lane line.**\n",
    "\n",
    "#### 7. Line segments with outlier slopes are excluded. (L/R)\n",
    "Prior to the definition of a continuous lane line, segments whose slopes are deemed to be outliers are removed. First, a soft maximum and minimum threshold are defined, call these $m_{max}$ and $m_{min}$. Second, compute the interquartile range (IQR) of all line segments with slopes, $m$ such that $m_{min} < m < m_{max}$. \n",
    "\n",
    "Let $Q1$ be the lower quartile of this restricted distribution of slopes in the allowed rasnge, and let $Q3$ be its upper quartile. \n",
    "\n",
    "Finally, any segment whose slope falls outside the range $[Q1 - 1.5 \\times IQR, Q3 + 1.5 \\times IQR]$, is defined to be an outlier, and is excluded from further processing. Note that there is no explicit exclusion of slopes greater than $m_{max}$ or less than $m_{min}$. Rather we model outliers based on a restricted range of slopes, and *only* remove segments based on the prooperties of this distribution. This effectively turns $m_{max}$ and $m_{min}$ into soft thresholds, enabling more organic outlier removal. \n",
    "\n",
    "#### 8. Linear modelling of lane lines (L/R)\n",
    "Using the collection of endpoints of all segments deemed *inliners* in step **7**, a linear model is fit for each lane via simple linear regression. \n",
    "\n",
    "#### 9. Exponential smoothing of lane parameters (L/R)\n",
    "To reduce jitteriness, take into account past knowledge of the location of lane lines,  and render the lane line model more robust, exponential smoothing is applied to the parameters of the linear fit described in **8**. Let $m_i, b_i$ be the slope and y-intercept of the linear model of a lane line computed in **8**, for frame $i$ of a video. We define $m_{i,smooth}, b_{i,smooth}$ as follows: \n",
    "\n",
    "$m_{i,smooth} = \\gamma m_i + (1 - \\gamma) m_{i-1, smooth}$\n",
    "\n",
    "$b_{i,smooth} = \\gamma b_i + (1 - \\gamma) b_{i-1, smooth}$\n",
    "\n",
    "where $\\gamma$ is a smoothing coefficient. Best results were achieved here for $\\gamma = 0.1$. This makes the lane modelling procedure heavily reliant on past results, and extremely conservative. While this is advantageous in cases where difficult conditions may momentarily impede lane-line identification, and works quite well for the videos provided here, realistically it would make adapting to rapid changes difficult.\n",
    "\n",
    "**Note** The smoothing procedure is only valid for video. When the pipeline is applied to single images, no smoothing takes place. \n",
    "\n",
    "#### 10. Drawing of lane lines. (L/R)\n",
    "The maximum and minimum vertical coordinates, $y_{min}, y_{max}$, of any line segment from step **6** are computed. \n",
    "\n",
    "Let $m, b$ be the (smoothed, if applicable) slope and (smoothed, if applicable) y-intercept of a linear model defined in **8,9**. A straight line is drawn from $(x_0, y_{min})$ to $(x_1, y_{max})$ for each lane, where $y_{min}= mx_0 + b$, and $y_{max} = mx_1 + b$.\n",
    "\n",
    "#### 11. Overlay the lane lines on the original image. \n",
    "The lane lines are drawn on the grayscale working image which has been heavily processed as part of the edge detection procedure. This working copy is combined with the original input image, enabling the input image to be reproduced with the additional lane lines drawn over it. \n",
    "\n",
    "## Shortcomings and Possible Improvements \n",
    "\n",
    "### Runtime \n",
    "One must imagine that a procedure for detecting lane lines will run in concert with many other simultaneous tasks on an autonomous vehicle. At present the pipeline is implemented with a single thread of execution. An updated pipeline, with more support for concurrent execution, perhas GPU support, particularly where operations on images are per-pixel, would be more efficient. \n",
    "\n",
    "### Obstacles, weather conditions, road conditions \n",
    "An approach to lane line detection based solely on vision and following the methodology  implemented here, is severly limited in all but near-ideal conditions. \n",
    "\n",
    "First, on a wet or icy road, where lane lines may be visually broken and the road very reflective, edge detection will undoubtedly be far more difficult. \n",
    "\n",
    "Obstacles on the road, proximal vehicles, and irregularl lane lines would all cause the proposed pipeline to faulter. \n",
    "\n",
    "Where road work is being performed, it is common for lane lines to be painted over in black, and new lanes defined alongside. This process creates spurious edges, which are difficult to distinguish from genuine lane lines. The use of different qualities of paint will present further challenges.\n",
    "\n",
    "On many roads, lane lines are not omnipresent. Indeed, one must stress that the videos provided, which depict *a nice day in California on a highway with almost no traffic* are a wildly simplified case, and totally unrepresentative of the real challenge of identifying lane lines, or developing lane-keeping methods for use \"in the wild.\" \n",
    "\n",
    "To make the pipline more robust in the face of the aforedescribed averse conditions, a first step would be more extensive image pre-processing, for the removal of glare and reflection. A hardware solution may also be necessary: a front facing camera is the equivalent of putting blinders on a horse, the detection procedure could be augmented by data from cameras positioned in the wheelarches of the vehicle. Specialized hardware filters (e.g. a *polarizing filter* fitted to the camera \n",
    "\n",
    "A human driver has a much richer notion of what a lane line represents, which enables safe-driving in averse conditions, and when there are no lane lines at all. Indeed, roads without lane lines should become more common, as it's been noted that a reduction in signage and  improves both the flow of traffic, and leads to fewer accidents [See here](https://www.theguardian.com/commentisfree/2016/feb/04/removal-road-markings-safer-fewer-accidents-drivers). \n",
    "\n",
    "### Curved lane lines \n",
    "A very obvious limitation of this simplistic approach is an innability to model curved lane lines in, for example, tight bends. Assuming the same ideal conditions in the provided videos, however, this can be very easily dealt with. \n",
    "\n",
    "First, a simple alternative would be fitting a bezier curve to each lane, rather than a linear model, which is a self-evident oversimplification. While a linear model was sufficient for the sake of completing the project in limited time, more suitable modelling approaches are available. \n",
    "\n",
    "Alternatively, the vertical position of line segments could be binned, and a linear model fit within each bin. Approaches abound, and I look forward to playing with this when more spare time sneaks up on me, or later in the course, as I assume the topic will present itself. \n",
    "\n",
    "### Inability to automatically adapt to unexpected conditions \n",
    "Lane line detection as implemented here cannot adapt to unexpected conditions, and the approach lacks a dynamic quality. Aside from what has been described above, the vehicle itself may be moved out of a central position. \n",
    "\n",
    "In all examples, the car is driving steadily, at a constant speed, in a single lane. No maneuvres are performed. A much more difficult task, is the detection of lane lines regardless of the path taken by the vehicle. \n",
    "\n",
    "In such cases it may, for instance, be more appropriate to detect all lanes on the road, rather than restricting attention to the markings immediately in front of the vehicle. The approch applied here and in the lessons is akin to putting blinders on the vehicle. More appropriate decisions can then be made by the models responsible for vehicle function and movement, in difficult situations. \n",
    "\n",
    "### Threshold based-approaches\n",
    "Finally, nearly all the algorithms applied in the pipeline as implemented here, and in the lessons, are based on thresholds. This *line in the sand* appraoch, is generally best replaced with a probabilistic method, where decisions can be made based on a computed degree of confidence in an estimate, rather than an arbitrary threshold. \n",
    "\n",
    "### Learning for adaptation \n",
    "Rather than vision alone, a hybrid solution relying on an underlying machine learning infrastcuture would, in many cases, render the detection pipeline more robust, and more adaptable to averse conditions. This would lead to a more adaptable model, and allow valuable measures of statistical confidence. \n",
    "\n",
    "However, a word of caution: it would be wildly irresponsible to rely solely on a machine learning solution in a mission critical, and life critical system. A hybrid approach is key, as any statistical model is, realisticaly, imperfect. One can imagine an emergency system which will take over and guide the vehicle safely to a stop, or safely enable the intervention of a human driver, in cases where the decisions being made by the learned model do not meet certain confidence requirements in exceptional sitautions. \n",
    "\n",
    "\n",
    "## A final note on implementation choices \n",
    "An effort has been made to adhere to the schema suggested by the lessons, and by the sample code and helper methods provided in this notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import cv2\n",
    "%matplotlib inline\n",
    "\n",
    "## Additional imports \n",
    "from collections import deque \n",
    "import math \n",
    "import os\n",
    "\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper methods (original/modified)\n",
    "\n",
    "The methods below were provided with the project outline. First, `hough_lines`, `draw_lines`, have been extended to support an additional paramter `smoother`. This parameter is to be an instance of `LaneSmoother` (see above).  \n",
    "\n",
    "Next, `draw_lines` has been extended to include \n",
    "\n",
    "1. Drawing of consensus, smoother lane markers, rather than individual line segments \n",
    "\n",
    "2. Removal of segments whose slopes are outliers or whose slopes do not fall within the range expected for valid lane lines.  \n",
    "\n",
    "3. Linear modelling of lane lines based on the extremeties of the segments computed in `hough_lines` \n",
    "\n",
    "4. Exponential smoothing of the parameters of linear lane-line models. \n",
    "\n",
    "A more in-depth discussion follows in the reflection. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def grayscale(img):\n",
    "    \"\"\"Applies the Grayscale transform\n",
    "    This will return an image with only one color channel\n",
    "    but NOTE: to see the returned image as grayscale\n",
    "    you should call plt.imshow(gray, cmap='gray')\"\"\"\n",
    "    return cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "def canny(img, low_threshold, high_threshold):\n",
    "    \"\"\"Applies the Canny transform\"\"\"\n",
    "    return cv2.Canny(img, low_threshold, high_threshold)\n",
    "\n",
    "def gaussian_blur(img, kernel_size):\n",
    "    \"\"\"Applies a Gaussian Noise kernel\"\"\"\n",
    "    return cv2.GaussianBlur(img, (kernel_size, kernel_size), 0)\n",
    "\n",
    "def region_of_innterest(img, vertices):\n",
    "    \"\"\"\n",
    "    Applies an image mask.\n",
    "\n",
    "    Only keeps the region of the image defined by the polygon\n",
    "    formed from `vertices`. The rest of the image is set to black.\n",
    "    \"\"\"\n",
    "    #defining a blank mask to start with\n",
    "    mask = np.zeros_like(img)\n",
    "\n",
    "    #defining a 3 channel or 1 channel color to fill the mask with depending on the input image\n",
    "    if len(img.shape) > 2:\n",
    "        channel_count = img.shape[2]  # i.e. 3 or 4 depending on your image\n",
    "        ignore_mask_color = (255,) * channel_count\n",
    "    else:\n",
    "        ignore_mask_color = 255\n",
    "\n",
    "    #filling pixels inside the polygon defined by \"vertices\" with the fill color\n",
    "    cv2.fillPoly(mask, vertices, ignore_mask_color)\n",
    "\n",
    "    #returning the image only where mask pixels are nonzero\n",
    "    masked_image = cv2.bitwise_and(img, mask)\n",
    "    return masked_image\n",
    "\n",
    "def draw_lines(img, lines, color=[255, 0, 0], thickness=10, smoother=None):\n",
    "    \"\"\" Draw lane lines, with removal of outlier slopes, and exponential smoothing.\n",
    "\n",
    "    img (Image)   : Current working copy of the frame/image (see `hough_lines`).\n",
    "\n",
    "    lines (array) : Extremeties of line segments computed in `hough_lines`.\n",
    "\n",
    "    color         : List of length 3, each entry must be in [0,255]. Specifies\n",
    "    the RGB color for drawing lane lines.\n",
    "\n",
    "    thickness     : Desired line thickness.\n",
    "\n",
    "    smoother      : An instance of LaneSmoother (see LaneSmoother). This object\n",
    "    holds and updates the parameters of the linear models of lane lines, applying\n",
    "    exponential smoothing.\n",
    "\n",
    "\n",
    "    Lane line segments are processed as follows:\n",
    "\n",
    "    (1) The are separated into right lanes (RL), and left lanes (LL) based\n",
    "    on the slope of the segments.\n",
    "\n",
    "    (2) Lane segments with outlier slopes are detected and excluded.\n",
    "\n",
    "    (3) Using the extremities of each lane segment, a linear model is fir\n",
    "    to the lane.\n",
    "\n",
    "    (4) If the application is video, and if an instance of LaneSmoother is provided,\n",
    "    exponential smoothing based on lanes detected in previous frames\n",
    "    is applied to the parameters of the model.\n",
    "\n",
    "    Returns:\n",
    "      None. Draws directly to the input image (`img`).\n",
    "    \"\"\"\n",
    "\n",
    "    ## For readability, define a few useful abstractions\n",
    "    f_linear_solve = lambda y, fit: math.floor((y-fit[1])/fit[0])\n",
    "    linear_model   = lambda x, y: np.polyfit(x=x, y=y, deg=1)\n",
    "\n",
    "    lines_flat = flatten(lines.tolist())\n",
    "    lane_params = list(map(line_params, lines_flat))\n",
    "\n",
    "    ## General constants\n",
    "    ymax = img.shape[0]\n",
    "    ymin  = min([min(y1, y2) for (x1,y1,x2,y2) in lines_flat])\n",
    "\n",
    "    ## The line segments corresponding to each lane are processed seperately. The lane\n",
    "    ## to which a segment belongs is determined by its slope. **Recalling that the origin\n",
    "    ## is in the upper left corner of the frame**, one may adopt the convention that\n",
    "    ## segments of the right lane have positive slope, while segments of the left\n",
    "    ## lane have negative slope.\n",
    "    ##\n",
    "    ## The right lane (positive slope) is processed first.\n",
    "\n",
    "    right        = [m > 0 for m,b in lane_params]\n",
    "    right_params = [(m,b) for i,(m,b) in enumerate(lane_params, 0) if right[i]]\n",
    "    right_out    = moutliers([m for m,b in right_params], 0.3, 1)\n",
    "\n",
    "    right_lines  = [line for i,line in enumerate(lines_flat, 0) if right[i]]\n",
    "    right_lines  = [line for i,line in enumerate(right_lines, 0) if not right_out[i]]\n",
    "\n",
    "    right_x = flatten([[x1,x2] for (x1,y1,x2,y2) in right_lines])\n",
    "    right_y = flatten([[y1,y2] for (x1,y1,x2,y2) in right_lines])\n",
    "\n",
    "    right_lane = linear_model(right_x, right_y)\n",
    "\n",
    "    if smoother:\n",
    "        right_lane = smoother.smooth(right_lane[0], right_lane[1], True)\n",
    "\n",
    "    cv2.line(img,\n",
    "             (f_linear_solve(ymax, right_lane), ymax),\n",
    "             (f_linear_solve(ymin, right_lane), ymin),\n",
    "             color, thickness)\n",
    "\n",
    "\n",
    "    left        = [m <= 0 for m,b in lane_params]\n",
    "    left_params = [(m,b) for i,(m,b) in enumerate(lane_params, 0) if left[i]]\n",
    "    left_out    = moutliers([m for m,b in left_params], -1, -0.3)\n",
    "\n",
    "    left_lines  = [line for i,line in enumerate(lines_flat, 0) if left[i]]\n",
    "    left_lines  = [line for i,line in enumerate(left_lines, 0) if not left_out[i]]\n",
    "\n",
    "    left_x = flatten([[x1,x2] for (x1,y1,x2,y2) in left_lines])\n",
    "    left_y = flatten([[y1,y2] for (x1,y1,x2,y2) in left_lines])\n",
    "\n",
    "    left_lane = linear_model(left_x, left_y)\n",
    "\n",
    "    if smoother:\n",
    "        left_lane = smoother.smooth(left_lane[0], left_lane[1], False)\n",
    "\n",
    "    cv2.line(img,\n",
    "             (f_linear_solve(ymin, left_lane), ymin),\n",
    "             (f_linear_solve(ymax, left_lane), ymax),\n",
    "             color, thickness)\n",
    "\n",
    "\n",
    "def hough_lines(img, rho, theta, threshold, min_line_len, max_line_gap, smoother=None):\n",
    "    \"\"\" Extract and draw hough lines.\n",
    "\n",
    "    Args:\n",
    "    img (Image): The output of a Canny transform.\n",
    "\n",
    "    smoother (LaneSmoother): Insance of LaneSmoother, or None. If None, we do not perform\n",
    "    any smoothing. Smoothing is only intended for video, where the linear models for the lane lines\n",
    "    visible in a given frame are updated based on the lanes detected in the previous frames.\n",
    "    For applications to single images, the value of `smoother` should be None, as smoothing\n",
    "    cannot be applied.\n",
    "\n",
    "    Returns:\n",
    "    An image with hough lines drawn.\n",
    "    \"\"\"\n",
    "    lines = cv2.HoughLinesP(img, rho, theta, threshold, np.array([]), minLineLength=min_line_len, maxLineGap=max_line_gap)\n",
    "    line_img = np.zeros((*img.shape, 3), dtype=np.uint8)\n",
    "\n",
    "    draw_lines(line_img, lines, smoother=smoother)\n",
    "    return line_img\n",
    "\n",
    "\n",
    "def weighted_img(img, initial_img, α=0.8,  β=1., λ=0.):\n",
    "    \"\"\"\n",
    "    `img` is the output of the hough_lines(), An image with lines drawn on it.\n",
    "    Should be a blank image (all black) with lines drawn on it.\n",
    "\n",
    "    `initial_img` should be the image before any processing.\n",
    "\n",
    "    The result image is computed as follows:\n",
    "\n",
    "    initial_img * α + img * β + λ\n",
    "    \"\"\"\n",
    "    return cv2.addWeighted(initial_img, α, img, β, λ)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Sources (additional)\n",
    "The following methods (and one class definition) have been added, and are not present in the original project outline. They are presented separately here for clarity. Below, you will find the following: \n",
    "\n",
    "1. `moutliers` A helper method for flagging outliers in a set of slopes based on the interquartile range of the distribution of slopes which fall between pecified minimum and maximum allowed values. \n",
    "\n",
    "2. `line_params` A helper method for computing the parameters of a line segment, given its endpoints. \n",
    "\n",
    "3. `flatten` A trivial helper method, for 'flattening' a list, one level deep (i.e. `[[1,2]]` becomes `[1,2]`). \n",
    "\n",
    "4. `LaneSmoother` Class whose responsibility is the application of exponential smoothing to the parameters of the linear lane-line model. See the class documentation for more information. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def moutliers(values, min_allowed, max_allowed):\n",
    "    \"\"\" Determine the outliers of a set of slopes.\n",
    "\n",
    "    Consider the distribution of slopes which fall\n",
    "    in the range [min_allowed, max_allowed].\n",
    "\n",
    "    Compute the interquartile range (IQR) of this\n",
    "    **restricted distribution** of slopes, and\n",
    "    define any slope that falls outside the range\n",
    "\n",
    "    [Q1 - 1.5(IQR) , Q3 + 1.5(IQR)]\n",
    "\n",
    "    as an outlier, where Q1 is the lower quartile, and Q3\n",
    "    is the upper quartile.\n",
    "\n",
    "    This method effectively turns min_allowed, max_allowed\n",
    "    into 'soft' limits, which is more natural given the\n",
    "    application.\n",
    "\n",
    "    Args:\n",
    "    values (List) : List of slope values to test.\n",
    "    min_allowed (Number) : The minimum allowed slope for the provided collection.\n",
    "    max_allowed (Number) : The maximum allowed slope for the provided collection.\n",
    "\n",
    "    Returns:\n",
    "    A list of booleans, indicating whether or not the\n",
    "    corresponding position in the input is an outlier. True indicates\n",
    "    an outliers, False indicates an inliner.\n",
    "    \"\"\"\n",
    "    quartiles = lambda x: np.percentile(x, np.arange(0, 100, 25))\n",
    "    iqr = lambda x: abs(x[2] - x[1])\n",
    "    in_range = lambda x: x > min_allowed and x < max_allowed\n",
    "\n",
    "    ## Compute quartiles based ONLY on the values within the allowed range.\n",
    "    values_q = quartiles([v for i,v in enumerate(values, 0) if in_range(values[i])])\n",
    "    values_q_lower = values_q[1] - 1.5*iqr(values_q)\n",
    "    values_q_upper = values_q[2] + 1.5*iqr(values_q)\n",
    "\n",
    "    return [(v < values_q_lower or v > values_q_upper) for v in values]\n",
    "\n",
    "\n",
    "\n",
    "def line_params(l):\n",
    "    \"\"\" Compute the parameters of the line l.\n",
    "\n",
    "    Args:\n",
    "    l (List): The elements, in order, are x1,y1,x2,y2\n",
    "\n",
    "    Returns:\n",
    "    Tuple, (m, b) the first element is ((y2-y1)/(x2-x1)),\n",
    "    the second is the value of the y-intercept.\n",
    "    \"\"\"\n",
    "\n",
    "    x1,y1,x2,y2 = l\n",
    "    m = 1e-5 if np.isclose((y2-y1),0.) or np.isclose((x2-x1), 0.) else ((y2-y1)/(x2-x1))\n",
    "    b = y1 - m*x1\n",
    "    return (m,b)\n",
    "\n",
    "def flatten(L):\n",
    "    \"\"\"\n",
    "    Flatten the list L (one level).\n",
    "    \"\"\"\n",
    "    return [elem for l in L for elem in l]\n",
    "\n",
    "class LaneSmoother:\n",
    "    \"\"\" Exponential smoothing of the parameters of the lane line.\n",
    "\n",
    "    Lane lines are modelled as a linear function of x-coordinate\n",
    "    in the image. This class applies simple exponential smoothing to\n",
    "    the parameters. Parameters are smoothed as:\n",
    "\n",
    "    m1 = gamma*m1 + m0*(1 - gamma)\n",
    "    b1 = gamma*b1 + b0*(1 - gamma)\n",
    "\n",
    "\n",
    "    Attributes:\n",
    "    left_prev (Dict): A dictionary {m: ...,b: ...} of the previous smoothed parameters. m is the\n",
    "    slope of the lane line, and b is the y-intercept.\n",
    "\n",
    "    right_prev (Dict): As above, but for the right lane.\n",
    "    \"\"\"\n",
    "    def __init__(self, gamma):\n",
    "        self.gamma = gamma\n",
    "\n",
    "        self.left_prev  = {'m': None, 'b': None}\n",
    "        self.right_prev = {'m': None, 'b': None}\n",
    "\n",
    "    def smooth(self, new_m, new_b, left):\n",
    "        \"\"\" Compute smoothed parameter estimates and update previously stored estimate.\n",
    "\n",
    "        The main working method of the LaneSmoother, class, `smooth` takes\n",
    "        a 'raw' slope and a 'raw' y-intercept, and applies exponential smoothing\n",
    "        with smoothing factor gamma. Note that the smoothing factor is supplied\n",
    "        at instantiation of the LaneSmoother class, and is constant throughout the\n",
    "        life of the object. New parameter estimates are computed as:\n",
    "\n",
    "        x1_smooth = (gamma * x1_orig) + (1- gamma)*x0\n",
    "\n",
    "        where x1_smoother is the updated smoothed parameter, x1_orig is the\n",
    "        parameter before smoothing, and x0 is the previous (smoothed) value\n",
    "        of the parameter.\n",
    "\n",
    "        Args:\n",
    "        new_m (Number)  : Slope to be smoothed.\n",
    "        new_b (Number)  : Y-intercept to be smoothed.\n",
    "        left  (Boolean) : Right or left lane?\n",
    "\n",
    "        Returns:\n",
    "        Smoohted parameter estimates for the slope, m,  and y-intercept, b, of the model,\n",
    "        as a tuple (m,b).\n",
    "        \"\"\"\n",
    "\n",
    "        this_prev = self.left_prev if left else self.right_prev\n",
    "\n",
    "        if this_prev['m'] and  this_prev['b']:\n",
    "            this_prev['m'] = new_m * self.gamma + (1 - self.gamma)*this_prev['m']\n",
    "            this_prev['b'] = new_b * self.gamma + (1 - self.gamma)*this_prev['b']\n",
    "        else:\n",
    "            this_prev['m'] = new_m\n",
    "            this_prev['b'] = new_b\n",
    "\n",
    "        return (this_prev['m'], this_prev['b'])\n",
    "\n",
    "\n",
    "\n",
    "def image_saturation(image, saturation_factor):\n",
    "    \"\"\" Change the saturation of an RGB image.\n",
    "\n",
    "    Args:\n",
    "    image (Image) : The image whose saturation we wish to change. Must be\n",
    "    cv2.RGB\n",
    "\n",
    "    saturation_factor (Number) : Factor by which we wish to change saturation.\n",
    "\n",
    "    Note that this method works by converting the image from RGB to HSV space\n",
    "    using opencv's cvtColor method.\n",
    "\n",
    "    Returns:\n",
    "        Image with modified saturation.\n",
    "    \"\"\"\n",
    "    image_working = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    (h, s, v) = cv2.split(image_working)\n",
    "    s = s*saturation_factor\n",
    "    s = np.clip(s,0,255)\n",
    "    image_working = cv2.merge([h,s,v])\n",
    "    image_working = cv2.cvtColor(image_working, cv2.COLOR_HSV2BGR)\n",
    "    return(image_working)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline\n",
    "More details are provided in the reflection. See the commentary below for an outline. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_image(image, smoother):\n",
    "    \"\"\" Detect and mark lane lines in an image.\n",
    "\n",
    "    Args:\n",
    "    image (Image) : An single image to process.\n",
    "\n",
    "    smoother (LaneSmoother) : Either an instance of LaneSmoother or None. If this\n",
    "    processing pipeline is being applied to single images, smoothing is not supported.\n",
    "\n",
    "\n",
    "    The pipeline is as follows:\n",
    "\n",
    "    (1) Increase image saturation by a factor of 2.\n",
    "    (2) Increase image contrast (alpha 1.0, beta -100)\n",
    "    (3) Convert to grayscale\n",
    "    (4) Guassian blur\n",
    "    (5) Canny edge detection\n",
    "    (6) Define region of interest\n",
    "    (7) Detect line segment via the Hough transform.\n",
    "       (7.1) Detect and exclude line segments deemed to be outliers for each lane\n",
    "       (7.2) Apply a linear model to each lane\n",
    "       (7.3) If applicable, smooth the parameters of the model describing each lane based\n",
    "             on previous iterations.\n",
    "    (8) Combine the overlay, where lane lines have been drawn, and the original image.\n",
    "\n",
    "    Returns:\n",
    "        A numpy.ndarray representing an image with marked lane lines.\n",
    "        Dimensions are identical to input image, color is preserved.\n",
    "    \"\"\"\n",
    "\n",
    "    image_working = image\n",
    "\n",
    "    xsize = image_working.shape[1]\n",
    "    ysize = image_working.shape[0]\n",
    "\n",
    "    ## Up saturation\n",
    "    image_working = image_saturation(image_working, 2)\n",
    "\n",
    "\n",
    "    ## Modify the contrast of the image. With the saturation\n",
    "    ## increase above ^ this makes yellow lane lines more\n",
    "    ## easily spotted in bright sunlight (easily observed\n",
    "    ## in the challenge video).\n",
    "    beta  = np.array([-100.0])\n",
    "    cv2.add(image_working, beta, image_working)\n",
    "\n",
    "\n",
    "    image_working = grayscale(image_working)\n",
    "\n",
    "    image_working = gaussian_blur(image_working, kernel_size=3)\n",
    "\n",
    "    image_working = canny(image_working, low_threshold=50, high_threshold=150)\n",
    "\n",
    "    ## The image here is considered as a 32 x 32 grid, to make it simpler to\n",
    "    ## reason about the space being defined as the ROI.\n",
    "    roi_vertices  = np.array([[(xsize*(3/32), ysize),\n",
    "                               (xsize*(15/32), ysize*(19/32)),\n",
    "                               (xsize*(17/32), ysize*(19/32)),\n",
    "                               (xsize, ysize)]], dtype='int32')\n",
    "\n",
    "    image_working = region_of_interest(image_working, vertices=roi_vertices)\n",
    "\n",
    "    image_working = hough_lines(image_working, rho=1, theta=1*(math.pi/180),\n",
    "                                threshold=15, min_line_len=30, max_line_gap=30,\n",
    "                                smoother=smoother)\n",
    "\n",
    "    result = weighted_img(image_working, image)\n",
    "\n",
    "    return result\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests on Images\n",
    "Images are saved in the `test_images` directory, please view them there. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_images = ['solidWhiteRight.jpg', 'solidYellowCurve.jpg',\n",
    "               'solidWhiteCurve.jpg', 'solidYellowLeft.jpg',\n",
    "               'solidYellowCurve2.jpg', 'whiteCarLaneSwitch.jpg']\n",
    "\n",
    "for image_path in test_images:\n",
    "    print(\"Processing \" + image_path + \"\\n\")\n",
    "    image = mpimg.imread('test_images/' + image_path)\n",
    "    res = process_image(image, smoother=None)\n",
    "    mpimg.imsave('test_images/test_' + image_path, res)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test on Videos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "white_output = 'white.mp4'\n",
    "smoother = LaneSmoother(0.1)\n",
    "clip1 = VideoFileClip(\"solidWhiteRight.mp4\")\n",
    "white_clip = clip1.fl_image(lambda frame: process_image(frame, smoother=smoother))\n",
    "\n",
    "%time white_clip.write_videofile(white_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(white_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "yellow_output = 'yellow.mp4'\n",
    "smoother = LaneSmoother(0.1)\n",
    "clip2 = VideoFileClip('solidYellowLeft.mp4')\n",
    "yellow_clip = clip2.fl_image(lambda frame: process_image(frame, smoother=smoother))\n",
    "\n",
    "%time yellow_clip.write_videofile(yellow_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(yellow_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Optional Challenge\n",
    "\n",
    "The pipeline is applied to all three vidoes here, however, the utility of the removal of outlier slopes is most evident in the processing of this challenge video, where line segments detected on the hood of the vehicle are excluded. See this reflection above. \n",
    "\n",
    "Increasing the saturation and contrast of each image to compensate for the effect of bright sunlight and an irregular road surface from 0:04 - 0:06 assisted in the detection of the yellow lane line for these portions of the image. \n",
    "\n",
    "Finally, applying exponential smoothing to the parameter of the linear model used to describe lane lines eliminated a large part of the jitteriness that would otherwise be observed in all provided videos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "challenge_output = 'extra.mp4'\n",
    "smoother = LaneSmoother(0.1)\n",
    "clip2 = VideoFileClip('challenge.mp4')\n",
    "challenge_clip = clip2.fl_image(lambda frame: process_image(frame, smoother=smoother))\n",
    "\n",
    "%time challenge_clip.write_videofile(challenge_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(challenge_output))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
